{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e691285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evauluation ---\n",
      "R2: 0.9563965355080849\n",
      "MAE: 6304.269375411323\n",
      "[ 1.45732913e+05  8.89236149e+03 -2.62466606e+04 -1.94373308e+04\n",
      " -2.43488992e+04  3.55997770e+04  8.18645302e+03  3.05084313e+02\n",
      "  7.94738373e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pete\\AppData\\Local\\Temp\\ipykernel_27848\\373871751.py:52: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  Fayetteville_home_sales_count = home_sales_count[(home_prices_df[\"StateName\"] == \"NC\")]\n",
      "C:\\Users\\Pete\\AppData\\Local\\Temp\\ipykernel_27848\\373871751.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_df_post_2008_with_sales_volume['Month'] = combined_df_post_2008_with_sales_volume['Date'].dt.month\n",
      "C:\\Users\\Pete\\AppData\\Local\\Temp\\ipykernel_27848\\373871751.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_df_post_2008_with_sales_volume['Day'] = combined_df_post_2008_with_sales_volume['Date'].dt.day\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error, mean_squared_error, r2_score\n",
    "from collections import Counter\n",
    "import scipy.stats as stats\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The Model\n",
    "home_prices_df = pd.read_csv(\"Zillow Home Data.csv\")\n",
    "hpi_df = pd.read_csv(\"housing_price_index.csv\")\n",
    "home_sales_count = pd.read_csv(\"Sold_Homes_US.csv\")\n",
    "mortgage_data = pd.read_csv(\"mortgage_rates.csv\")\n",
    "\n",
    "\n",
    "Fayetteville_home_price_DF = home_prices_df[(home_prices_df[\"StateName\"] == \"NC\") & (home_prices_df[\"RegionName\"] == \"Fayetteville, NC\")]\n",
    "hpi_df = pd.read_csv(\"housing_price_index.csv\")\n",
    "\n",
    "east_north = hpi_df[hpi_df['place_name'] == \"East North Central Division\"] \n",
    "monthly = east_north[east_north[\"frequency\"] == 'monthly']\n",
    "clean_hpi_data = monthly.drop(['hpi_type', 'hpi_flavor', 'frequency', 'level', 'place_name', 'place_id'], axis= 1)\n",
    "\n",
    "fayetteville_prices = Fayetteville_home_price_DF.drop(columns=[\"RegionID\", \"SizeRank\", \"RegionName\", \"RegionType\", \"StateName\"]).T\n",
    "fayetteville_prices.columns = [\"Price\"]\n",
    "fayetteville_prices.index = pd.to_datetime(fayetteville_prices.index)\n",
    "\n",
    "Fayetteville_home_sales_count = home_sales_count[(home_prices_df[\"StateName\"] == \"NC\")]\n",
    "Fay_mean_sales_by_month = Fayetteville_home_sales_count.mean(axis=0, numeric_only=True).to_frame().T\n",
    "Fay_mean_sales_by_month = Fay_mean_sales_by_month.drop([\"RegionID\", \"SizeRank\"], axis=1)\n",
    "Fay_mean_sales_by_month.columns = pd.to_datetime(Fay_mean_sales_by_month.columns, )\n",
    "test_df = Fay_mean_sales_by_month.T\n",
    "Fay_mean_sales_by_month_T = Fay_mean_sales_by_month.T\n",
    "Fay_mean_sales_by_month_T = Fay_mean_sales_by_month_T.reset_index()\n",
    "Fay_mean_sales_by_month_T.columns = ['Date', 'Sales Per Month']  # Rename columns\n",
    "\n",
    "\n",
    "clean_df = Fayetteville_home_price_DF.drop([\"RegionID\", \"SizeRank\", \"RegionName\", \"StateName\", \"RegionType\"], axis=1).T\n",
    "cleaner_df = clean_df.reset_index()\n",
    "df = cleaner_df.rename(columns={106: 'price', 'index': 'Date'})\n",
    "df['Date'] = pd.to_datetime(df['Date'])                   \n",
    "df[\"year\"] = df['Date'].dt.year\n",
    "\n",
    "# annual_avg = df.groupby('year')['price'].mean().reset_index()\n",
    "rates_and_cost = pd.concat([mortgage_data, fayetteville_prices], ignore_index=True)\n",
    "\n",
    "# * Datasets to pull from:\n",
    "# 1. df = average prices in Fayetteville by month\n",
    "# 2. annual_avg - average prices in Fayetteville by year \n",
    "# 3. mortgage_data = mortgage interest rate 30 year fixed by month since Jan 2000\n",
    "# 4. Fay_mean_sales_by_month = transaction volume broked down by month since Feb 2008\n",
    "\n",
    "# * conflict_periods_2 = [\n",
    "    \n",
    "#     (\"2008-02-29\", \"2011-12-31\", \"War on Terror\"),\n",
    "    \n",
    "#     (\"2008-02-29\", \"2009-06-30\", \"Great Recession\"),\n",
    "    \n",
    "#     (\"2011-01-01\", \"2014-12-31\", \"Arab Spring\"),\n",
    "    \n",
    "#     (\"2014-02-01\", \"2014-12-31\", \"Crimea Annexation\"),\n",
    "    \n",
    "#     (\"2018-07-01\", \"2019-12-31\", \"US-China Trade War\"),\n",
    "    \n",
    "#     (\"2020-03-01\", \"2022-06-30\", \"COVID-19\"),\n",
    "    \n",
    "#     (\"2022-02-01\", \"2025-01-01\", \"Russia-Ukraine War\"),\n",
    "    \n",
    "#     (\"2023-10-01\", \"2025-01-01\", \"Israel–Hamas Escalation\")]\n",
    "\n",
    "Fay_mean_sales_by_month = Fay_mean_sales_by_month.T\n",
    "Fay_mean_sales_by_month = Fay_mean_sales_by_month.reset_index()\n",
    "Fay_mean_sales_by_month.columns = ['Date', 'Sales_Volume']\n",
    "\n",
    "mortgage_data['observation_date'] = pd.to_datetime(mortgage_data['observation_date'])\n",
    "\n",
    "mortgage_data.rename(columns={'observation_date': 'Date'}, inplace=True)\n",
    "\n",
    "combined_df = df.merge(mortgage_data, on='Date', how='outer')\\\n",
    "                .merge(Fay_mean_sales_by_month, on='Date', how='outer')\n",
    "\n",
    "\n",
    "# Make sure you have a 'year' column\n",
    "combined_df['year'] = combined_df['Date'].dt.year\n",
    "\n",
    "# Fill NaN in SalesVolume with mean SalesVolume of that year\n",
    "combined_df['Sales_Volume'] = combined_df.groupby('year')['Sales_Volume']\\\n",
    "    .transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "\n",
    "combined_df['price'] = combined_df.groupby('year')['price'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "combined_df['MORTGAGE30US'] = combined_df.groupby('year')['MORTGAGE30US'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "#  1 = Economic \n",
    "#  2 = US War\n",
    "#  3 = International Conlfict\n",
    "\n",
    "conflict_periods_years = [\n",
    "    (2008, 2009, 1),  # Great Recession → Economic\n",
    "    (2008, 2011, 2),  # War on Terror → US War\n",
    "    (2011, 2014, 3),  # Arab Spring → International Conflict\n",
    "    (2014, 2014, 3),  # Crimea Annexation → International Conflict\n",
    "    (2018, 2019, 1),  # US-China Trade War → Economic\n",
    "    (2020, 2022, 1),  # COVID → Economic\n",
    "    (2022, 2025, 3),  # Russia-Ukraine → International Conflict\n",
    "    (2023, 2025, 3)   # Israel–Hamas → International Conflict\n",
    "]\n",
    "\n",
    "\n",
    "# Ensure you have a 'year' column\n",
    "combined_df['year'] = combined_df['Date'].dt.year\n",
    "\n",
    "# Initialize the conflict column with default value, e.g. 0 (no conflict)\n",
    "combined_df['conflict_type'] = 0\n",
    "\n",
    "# Iterate over conflict periods and assign codes\n",
    "for start_year, end_year, code in conflict_periods_years:\n",
    "    mask = (combined_df['year'] >= start_year) & (combined_df['year'] <= end_year)\n",
    "    combined_df.loc[mask, 'conflict_type'] = code\n",
    "\n",
    "\n",
    "combined_df_post_2008_with_sales_volume = combined_df[combined_df['Date'] >= '2008-06-30']\n",
    "\n",
    "combined_df_no_sales_volume = combined_df[combined_df['Date'] <= '2008-06-30']\n",
    "combined_df_no_sales_volume = combined_df_no_sales_volume.drop('Sales_Volume', axis = 1)\n",
    "\n",
    "combined_df_post_2008_with_sales_volume['Month'] = combined_df_post_2008_with_sales_volume['Date'].dt.month\n",
    "combined_df_post_2008_with_sales_volume['Day'] = combined_df_post_2008_with_sales_volume['Date'].dt.day\n",
    "\n",
    "combined_df_post_2008_with_sales_volume = combined_df_post_2008_with_sales_volume.drop('Date', axis = 1)\n",
    "\n",
    "\n",
    "#  PR3EDICTING \n",
    "X_sales_volume = combined_df_post_2008_with_sales_volume.drop('price', axis=1)\n",
    "y_sales_volume = combined_df_post_2008_with_sales_volume['price']\n",
    "\n",
    "X_volume_train, X_volume_test, y_volume_train, y_volume_test = train_test_split(X_sales_volume, y_sales_volume, test_size=.2)\n",
    "\n",
    "#  PIPELINE\n",
    "\n",
    "numeric_features = ['year', 'MORTGAGE30US', 'Sales_Volume']\n",
    "categorical_features = ['conflict_type']\n",
    "\n",
    "numeric_transformation = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy= 'mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('num', numeric_transformation, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "linear_price_model = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('classification', LinearRegression())\n",
    "])\n",
    "\n",
    "linear_price_model.fit(X_volume_train, y_volume_train)\n",
    "# # After linear_price_model.fit()\n",
    "\n",
    "# # After linear_price_model.fit()\n",
    "\n",
    "# # Fetch feature names from preprocessor\n",
    "# numeric_features = ['year', 'MORTGAGE30US', 'Sales_Volume']\n",
    "# categorical_features = ['conflict_type']\n",
    "\n",
    "# onehot_columns = linear_price_model.named_steps['preprocessing'].named_transformers_['cat']\\\n",
    "#     .named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "\n",
    "# all_features = numeric_features + list(onehot_columns)\n",
    "\n",
    "# # Extract coefficients\n",
    "# coefficients = linear_price_model.named_steps['classification'].coef_\n",
    "\n",
    "# # Create DataFrame for inspection\n",
    "# feature_importance_df = pd.DataFrame({\n",
    "#     'Feature': all_features,\n",
    "#     'Coefficient': coefficients\n",
    "# }).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# st.write(\"### Linear Model Coefficients (Feature Importance Proxy)\")\n",
    "# st.dataframe(feature_importance_df)\n",
    "\n",
    "# # Optional visualization\n",
    "# st.bar_chart(feature_importance_df.set_index('Feature'))\n",
    "\n",
    "\n",
    "\n",
    "# T3STING\n",
    "\n",
    "linear_predictions = linear_price_model.predict(X_volume_test)\n",
    "\n",
    "mae = mean_absolute_error(y_volume_test, linear_predictions)\n",
    "r2 = r2_score(y_volume_test, linear_predictions)\n",
    "print(\"\\n--- Evauluation ---\")\n",
    "# print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(linear_price_model.named_steps['classification'].coef_)\n",
    "# Streamlit UI\n",
    "st.title(\"🏡 Linear Housing Price Predictor (Fayetteville, NC)\")\n",
    "\n",
    "st.write(f\"### Model Performance:\\n- R2 Score: {r2:.2f}\\n- MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc912de",
   "metadata": {},
   "source": [
    "# Save with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "393ffccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_price_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(linear_price_model, 'linear_price_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245de383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5693bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1625d02",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
